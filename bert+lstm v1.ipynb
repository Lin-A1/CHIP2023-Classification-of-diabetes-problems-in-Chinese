{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a728479-3f8f-4f89-a1c4-acd63f509389",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import jieba\n",
    "import re\n",
    "from transformers import BertTokenizer, BertForSequenceClassification,BertModel\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# 检查是否有可用的GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6fd29d6-2d4d-4d56-84ff-e9809e041bc1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at model/bret_base_chinese/model were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# 加载BERT模型和tokenizer，并将它们移动到GPU上\n",
    "tokenizer = BertTokenizer.from_pretrained(\"model/bret_base_chinese/tokenizer\")\n",
    "bert_model = BertModel.from_pretrained(\"model/bret_base_chinese/model\").to(device)\n",
    "\n",
    "# 冻结BERT模型参数\n",
    "for param in bert_model.parameters():\n",
    "    param.requires_grad_(False)\n",
    "\n",
    "# 解冻部分BERT模型参数\n",
    "for param in bert_model.encoder.layer[-3:].parameters():\n",
    "    param.requires_grad_(True)\n",
    "\n",
    "    \n",
    "# 创建一个自定义的双向LSTM模型\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, bert_model, lstm_hidden_dim, num_labels, dropout_prob=0.2):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.bert_model = bert_model\n",
    "        self.lstm = nn.LSTM(input_size=bert_model.config.hidden_size,\n",
    "                            hidden_size=lstm_hidden_dim,\n",
    "                            num_layers=2,\n",
    "                            batch_first=True,\n",
    "                            dropout=dropout_prob,\n",
    "                            bidirectional=True)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.fc = nn.Linear(lstm_hidden_dim * 2, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # 使用BERT提取特征\n",
    "        with torch.no_grad():  # 在BERT模型中不计算梯度\n",
    "            outputs = self.bert_model(input_ids, attention_mask=attention_mask)\n",
    "            bert_hidden_states = outputs.last_hidden_state\n",
    "\n",
    "        # 将BERT的输出传递给LSTM\n",
    "        lstm_output, _ = self.lstm(bert_hidden_states)\n",
    "        lstm_output = self.dropout(lstm_output)\n",
    "\n",
    "        # 获取最后一个时间步的输出\n",
    "        last_lstm_output = lstm_output[:, -1, :]\n",
    "\n",
    "        # 使用全连接层进行分类\n",
    "        logits = self.fc(last_lstm_output)\n",
    "        return logits\n",
    "\n",
    "# 定义模型参数\n",
    "lstm_hidden_dim = 256\n",
    "num_labels = 6  \n",
    "dropout_prob = 0.2 \n",
    "\n",
    "# 创建BERT+LSTM模型\n",
    "model = LSTMClassifier(bert_model, lstm_hidden_dim, num_labels, dropout_prob).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8a3b7e3-9217-4e1d-9759-d8c38ea26489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "MAX_LEN = 80\n",
    "\n",
    "def preprocess_data(df, tokenizer, max_len):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    labels = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        text = row[0]\n",
    "        label = row[1]\n",
    "\n",
    "        inputs = tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        input_ids.append(inputs['input_ids'])\n",
    "        attention_masks.append(inputs['attention_mask'])\n",
    "        labels.append(label)\n",
    "\n",
    "    input_ids = torch.cat(input_ids, dim=0).to(device)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0).to(device)\n",
    "    labels = torch.tensor(labels, dtype=torch.long).to(device)\n",
    "\n",
    "    return input_ids, attention_masks, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "686f0b70-920d-4144-add6-a1111056e926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备训练数据和验证数据\n",
    "train_df = pd.read_table('input/train.txt',header=None)\n",
    "dev_df = pd.read_table('input/dev.txt',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a16551fd-7d2b-47c5-af42-ad0a140789d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # 去除特殊字符、符号和数字\n",
    "    cleaned_text = re.sub(r'[^\\u4e00-\\u9fa5a-zA-Z\\s]', '', text)\n",
    "    return cleaned_text\n",
    "\n",
    "train_df[0] = train_df[0].map(clean_text)\n",
    "dev_df[0] = dev_df[0].map(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7848996b-a014-4c55-8e44-03d40116d792",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_ids, train_attention_masks, train_labels = preprocess_data(train_df, tokenizer, MAX_LEN)\n",
    "dev_input_ids, dev_attention_masks, dev_labels = preprocess_data(dev_df, tokenizer, MAX_LEN)\n",
    "\n",
    "# 创建TensorDataset和DataLoader\n",
    "train_dataset = TensorDataset(train_input_ids, train_attention_masks, train_labels)\n",
    "dev_dataset = TensorDataset(dev_input_ids, dev_attention_masks, dev_labels)\n",
    "\n",
    "train_batch_size = 64\n",
    "dev_batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "dev_dataloader = DataLoader(dev_dataset, batch_size=dev_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd43a7ad-7171-4d4e-9a8e-41c2ab364115",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Average Loss: 1.1407\tTest_Accuracy: 70.80%\n",
      "Epoch 2/50, Average Loss: 0.7084\tTest_Accuracy: 73.40%\n",
      "Epoch 3/50, Average Loss: 0.6303\tTest_Accuracy: 74.00%\n",
      "Epoch 4/50, Average Loss: 0.5868\tTest_Accuracy: 79.20%\n",
      "Epoch 5/50, Average Loss: 0.5545\tTest_Accuracy: 79.80%\n",
      "Epoch 6/50, Average Loss: 0.5198\tTest_Accuracy: 80.30%\n",
      "Epoch 7/50, Average Loss: 0.5143\tTest_Accuracy: 80.00%\n",
      "Epoch 8/50, Average Loss: 0.4969\tTest_Accuracy: 79.70%\n",
      "Epoch 9/50, Average Loss: 0.4723\tTest_Accuracy: 80.30%\n",
      "Epoch 10/50, Average Loss: 0.4593\tTest_Accuracy: 80.90%\n",
      "Epoch 11/50, Average Loss: 0.4361\tTest_Accuracy: 82.20%\n",
      "Epoch 12/50, Average Loss: 0.4382\tTest_Accuracy: 82.40%\n",
      "Epoch 13/50, Average Loss: 0.4099\tTest_Accuracy: 81.90%\n",
      "Epoch 14/50, Average Loss: 0.4070\tTest_Accuracy: 82.90%\n",
      "Epoch 15/50, Average Loss: 0.3823\tTest_Accuracy: 83.00%\n",
      "Epoch 16/50, Average Loss: 0.3656\tTest_Accuracy: 82.20%\n",
      "Epoch 17/50, Average Loss: 0.3742\tTest_Accuracy: 82.40%\n",
      "Epoch 18/50, Average Loss: 0.3626\tTest_Accuracy: 84.80%\n",
      "Epoch 19/50, Average Loss: 0.3416\tTest_Accuracy: 84.70%\n",
      "Epoch 20/50, Average Loss: 0.3314\tTest_Accuracy: 83.30%\n",
      "Epoch 21/50, Average Loss: 0.3185\tTest_Accuracy: 82.10%\n",
      "Epoch 22/50, Average Loss: 0.3182\tTest_Accuracy: 83.50%\n",
      "Epoch 23/50, Average Loss: 0.2951\tTest_Accuracy: 83.60%\n",
      "Epoch 24/50, Average Loss: 0.2959\tTest_Accuracy: 84.20%\n",
      "Epoch 25/50, Average Loss: 0.2892\tTest_Accuracy: 84.90%\n",
      "Epoch 26/50, Average Loss: 0.2748\tTest_Accuracy: 84.50%\n",
      "Epoch 27/50, Average Loss: 0.2627\tTest_Accuracy: 83.90%\n",
      "Epoch 28/50, Average Loss: 0.2646\tTest_Accuracy: 84.10%\n",
      "Epoch 29/50, Average Loss: 0.2500\tTest_Accuracy: 84.60%\n",
      "Epoch 30/50, Average Loss: 0.2395\tTest_Accuracy: 84.70%\n",
      "Epoch 31/50, Average Loss: 0.2364\tTest_Accuracy: 85.10%\n",
      "Epoch 32/50, Average Loss: 0.2269\tTest_Accuracy: 84.70%\n",
      "Epoch 33/50, Average Loss: 0.2292\tTest_Accuracy: 84.70%\n",
      "Epoch 34/50, Average Loss: 0.2281\tTest_Accuracy: 85.00%\n",
      "Epoch 35/50, Average Loss: 0.2001\tTest_Accuracy: 84.10%\n",
      "Epoch 36/50, Average Loss: 0.1919\tTest_Accuracy: 85.00%\n",
      "Epoch 37/50, Average Loss: 0.1985\tTest_Accuracy: 85.20%\n",
      "Epoch 38/50, Average Loss: 0.2099\tTest_Accuracy: 84.00%\n",
      "Epoch 39/50, Average Loss: 0.1906\tTest_Accuracy: 85.10%\n",
      "Epoch 40/50, Average Loss: 0.1732\tTest_Accuracy: 85.30%\n",
      "Epoch 41/50, Average Loss: 0.1836\tTest_Accuracy: 85.10%\n",
      "Epoch 42/50, Average Loss: 0.1700\tTest_Accuracy: 85.00%\n",
      "Epoch 43/50, Average Loss: 0.1520\tTest_Accuracy: 84.30%\n",
      "Epoch 44/50, Average Loss: 0.1575\tTest_Accuracy: 85.50%\n",
      "Epoch 45/50, Average Loss: 0.1651\tTest_Accuracy: 84.20%\n",
      "Epoch 46/50, Average Loss: 0.1530\tTest_Accuracy: 84.40%\n",
      "Epoch 47/50, Average Loss: 0.1475\tTest_Accuracy: 84.40%\n",
      "Epoch 48/50, Average Loss: 0.1605\tTest_Accuracy: 85.60%\n",
      "Epoch 49/50, Average Loss: 0.1583\tTest_Accuracy: 84.40%\n",
      "Epoch 50/50, Average Loss: 0.1367\tTest_Accuracy: 86.40%\n"
     ]
    }
   ],
   "source": [
    "# 定义优化器和损失函数\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# 训练模型\n",
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 前向传播\n",
    "        logits = model(input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # 计算交叉熵损失\n",
    "        loss = loss_fn(logits, labels)\n",
    "        \n",
    "        # 反向传播和参数更新\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Average Loss: {avg_loss:.4f}\",end='\\t')\n",
    "\n",
    "    # 在验证集上评估模型性能\n",
    "    model.eval()\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "\n",
    "    for batch in dev_dataloader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        with torch.no_grad():\n",
    "            logits = model(input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # 计算预测\n",
    "        val_preds.extend(logits.argmax(dim=1).tolist())\n",
    "        val_labels.extend(labels.tolist())\n",
    "\n",
    "    \n",
    "    correct_predictions = [1 if p == t else 0 for p, t in zip(val_preds, val_labels)]\n",
    "    accuracy = sum(correct_predictions) / len(correct_predictions)\n",
    "    print(f'Test_Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc043d7c-dabf-4b3d-9fe0-dad2a7236b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_table('input/dev.txt',header=None)\n",
    "\n",
    "# 数据预处理\n",
    "test_input_ids, test_attention_masks, _ = preprocess_data(test_df, tokenizer, MAX_LEN)\n",
    "\n",
    "# 创建 DataLoader\n",
    "test_dataset = TensorDataset(test_input_ids, test_attention_masks)\n",
    "test_batch_size = 64\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=test_batch_size)\n",
    "\n",
    "# 将模型设置为评估模式\n",
    "model.eval()\n",
    "\n",
    "# 存储预测结果\n",
    "predictions = []\n",
    "\n",
    "# 遍历测试数据并进行预测\n",
    "for batch in test_dataloader:\n",
    "    input_ids, attention_mask = batch\n",
    "    input_ids = input_ids.to(device)\n",
    "    attention_mask = attention_mask.to(device)\n",
    "    with torch.no_grad():\n",
    "        # 前向传播\n",
    "        logits = model(input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "    # 计算预测\n",
    "    predicted_labels = logits.argmax(dim=1).tolist()\n",
    "    predictions.extend(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4db653b0-901d-49b4-bd04-f0799c71c060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.00%\n"
     ]
    }
   ],
   "source": [
    "true_labels = test_df[1]\n",
    "\n",
    "# 计算准确度\n",
    "correct_predictions = [1 if p == t else 0 for p, t in zip(predictions, true_labels)]\n",
    "accuracy = sum(correct_predictions) / len(correct_predictions)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2a366f-eda3-40f1-9bd6-cbd8d242abe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d560020c-1308-4138-b5f7-02b4f77fa04d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
