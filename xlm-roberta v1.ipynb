{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0eb6d148-1a27-4de7-ab96-fb1e2b810e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at model/XLM-RoBERTa and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([20, 768]) in the checkpoint and torch.Size([6, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([20]) in the checkpoint and torch.Size([6]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\tTraining Loss: 1.1501\tTraining Accuracy: 0.5692\tValidation Accuracy: 0.7760\n",
      "Epoch 2:\tTraining Loss: 0.6508\tTraining Accuracy: 0.7868\tValidation Accuracy: 0.8180\n",
      "Epoch 3:\tTraining Loss: 0.4576\tTraining Accuracy: 0.8622\tValidation Accuracy: 0.8390\n",
      "Epoch 4:\tTraining Loss: 0.3843\tTraining Accuracy: 0.8763\tValidation Accuracy: 0.8560\n",
      "Epoch 5:\tTraining Loss: 0.3122\tTraining Accuracy: 0.8992\tValidation Accuracy: 0.8550\n",
      "Epoch 6:\tTraining Loss: 0.2628\tTraining Accuracy: 0.9132\tValidation Accuracy: 0.8550\n",
      "Epoch 7:\tTraining Loss: 0.2016\tTraining Accuracy: 0.9370\tValidation Accuracy: 0.8580\n",
      "Epoch 8:\tTraining Loss: 0.1543\tTraining Accuracy: 0.9512\tValidation Accuracy: 0.8560\n",
      "Epoch 9:\tTraining Loss: 0.1137\tTraining Accuracy: 0.9672\tValidation Accuracy: 0.8570\n",
      "Epoch 10:\tTraining Loss: 0.0892\tTraining Accuracy: 0.9718\tValidation Accuracy: 0.8560\n",
      "Epoch 11:\tTraining Loss: 0.0736\tTraining Accuracy: 0.9792\tValidation Accuracy: 0.8560\n",
      "Epoch 12:\tTraining Loss: 0.0766\tTraining Accuracy: 0.9780\tValidation Accuracy: 0.8560\n",
      "Epoch 13:\tTraining Loss: 0.0782\tTraining Accuracy: 0.9773\tValidation Accuracy: 0.8560\n",
      "Epoch 14:\tTraining Loss: 0.0747\tTraining Accuracy: 0.9787\tValidation Accuracy: 0.8560\n",
      "Epoch 15:\tTraining Loss: 0.0725\tTraining Accuracy: 0.9797\tValidation Accuracy: 0.8560\n",
      "Epoch 16:\tTraining Loss: 0.0743\tTraining Accuracy: 0.9795\tValidation Accuracy: 0.8560\n",
      "Epoch 17:\tTraining Loss: 0.0726\tTraining Accuracy: 0.9792\tValidation Accuracy: 0.8560\n",
      "Epoch 18:\tTraining Loss: 0.0757\tTraining Accuracy: 0.9777\tValidation Accuracy: 0.8560\n",
      "Epoch 19:\tTraining Loss: 0.0752\tTraining Accuracy: 0.9775\tValidation Accuracy: 0.8560\n",
      "Epoch 20:\tTraining Loss: 0.0778\tTraining Accuracy: 0.9762\tValidation Accuracy: 0.8560\n",
      "Training finished. Final Evaluation on Dev Set:\n",
      "Validation Accuracy: 0.8560\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# 设置PyTorch随机种子\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# 设置Python的随机种子\n",
    "random.seed(seed)\n",
    "\n",
    "# 设置NumPy的随机种子\n",
    "np.random.seed(seed)\n",
    "\n",
    "# 加载数据\n",
    "train_df = pd.read_table('input/train.txt', header=None)\n",
    "dev_df = pd.read_table('input/dev.txt', header=None)\n",
    "\n",
    "# 设置模型和tokenizer\n",
    "model_name = \"model/XLM-RoBERTa\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=6, ignore_mismatched_sizes=True)\n",
    "\n",
    "# 添加Dropout层\n",
    "dropout_rate = 0.2\n",
    "model.classifier.dropout = nn.Dropout(p=dropout_rate)\n",
    "\n",
    "# 修改模型的输出层\n",
    "num_labels = 6  # 新的类别数\n",
    "model.classifier.out_proj = nn.Linear(in_features=768, out_features=num_labels, bias=True)\n",
    "\n",
    "# 数据预处理\n",
    "def preprocess_data(df, tokenizer, max_length=64):\n",
    "    texts = df[0].tolist()\n",
    "    labels = df[1].tolist()\n",
    "    inputs = tokenizer(texts, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
    "    labels = torch.tensor(labels)\n",
    "    return inputs, labels\n",
    "\n",
    "train_inputs, train_labels = preprocess_data(train_df, tokenizer)\n",
    "dev_inputs, dev_labels = preprocess_data(dev_df, tokenizer)\n",
    "\n",
    "# 创建数据加载器\n",
    "train_batch_size = 16  # 训练批次大小\n",
    "eval_batch_size = 16  # 评估批次大小\n",
    "train_dataset = TensorDataset(train_inputs['input_ids'], train_inputs['attention_mask'], train_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "dev_dataset = TensorDataset(dev_inputs['input_ids'], dev_inputs['attention_mask'], dev_labels)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=eval_batch_size, shuffle=False)\n",
    "\n",
    "# 定义损失函数\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# 定义优化器和学习率调度器\n",
    "learning_rate = 5e-05\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-08)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=len(train_loader) * 1, num_training_steps=len(train_loader) * 10)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # 计算损失\n",
    "        loss = loss_fn(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # 累加损失值\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # 计算准确率\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        correct_predictions += torch.sum(preds == labels).item()\n",
    "        total_predictions += len(labels)\n",
    "    \n",
    "    # 计算平均损失\n",
    "    average_loss = total_loss / len(train_loader)\n",
    "\n",
    "    # 输出训练集的损失和准确率\n",
    "    print(f\"Epoch {epoch + 1}:\", end='\\t')\n",
    "    print(f\"Training Loss: {average_loss:.4f}\", end='\\t')\n",
    "    train_accuracy = correct_predictions / total_predictions\n",
    "    print(f\"Training Accuracy: {train_accuracy:.4f}\", end='\\t')\n",
    "\n",
    "    # 在每个训练周期结束后评估模型并输出验证集的准确率\n",
    "    model.eval()\n",
    "    dev_preds = []\n",
    "    dev_true = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dev_loader:\n",
    "            input_ids, attention_mask, labels = batch\n",
    "            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            dev_preds.extend(preds.cpu().numpy())\n",
    "            dev_true.extend(labels.cpu().numpy())\n",
    "\n",
    "    dev_accuracy = accuracy_score(dev_true, dev_preds)\n",
    "    print(f\"Validation Accuracy: {dev_accuracy:.4f}\")\n",
    "\n",
    "# 最后输出模型的评估结果\n",
    "print(\"Training finished. Final Evaluation on Dev Set:\")\n",
    "dev_accuracy = accuracy_score(dev_true, dev_preds)\n",
    "print(f\"Validation Accuracy: {dev_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f52a2e4-5080-4629-a679-3c8067351ad6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
